# 数据伦理复习

#### Lecture 1 Cont‘d

（1）数据的有效性（Data Validity），错误的数据会导致错误的决策，正确的数据导致正确决策的示范。

1. 数据样本的代表性，手上拥有的数据并不一定代表整体数据，也并不一定代表将来的数据

   (I)有时候很重要：民意调查

   (II)有时候不那么重要：产品反馈

2. 数据样本的特征/属性选择：特征选择是否合理，特征值分布是否平衡

3. 利用统计工具衡量样本特征分布的平衡性（Ranking,Matching,Propensity weighting）

4. 数据处理引入错误:数据采集出错，执行ETL(Extract-Transform-Load)数据类型不一致，数据损坏和丢失

（2）算法公平性（Algorithmic Fairness）：

1. AI算法会放大数据样本的偏差：最小化训练误差≠最公平
2. 人为因素导致算法结果偏差
3. 算法黑盒化导致公平性问题难以纠正：深度神经网络算法$\rightarrow$一些领域（如Finance）不青睐黑盒
4. 大数据算法结果的误导性：相关变量$\neq$变量相关

（3）Sum：如何做到遵守数据伦理：敬畏数据，思考后果，超前思维

#### Lecture 2 数据所有权

##### 注意GDPR: General Data Protection Regulation

<u>“两会关注数据所有权问题”</u>

1. 无数公民无偿提供的数据，被极少数人控制，现在急需要在立法上明确数据的权属问题。

2. 信息泄露事件发生后，由于数据的权属不明，国家安全法、刑法、刑诉法等对此都没有明确，没有法律依据，处理起来会非常难。
3. 如果数据的所有权明确，未经允许拿取、使用我的数据，法律上属于盗窃行为。如果把数据看成是财务，如果偷盗等于偷盗了我的资产。如果泄露了与国家安全相关的数据，实际上比泄露国家情报还严重。如果泄露公民隐私数据，就侵犯了公民个人隐私。

（1）谁拥有数据？数据产生者（数据主体）和收集者（经过加工/原创工作的数据）共同拥有

case：淘宝和美景：虽然来源于原始用户信息数据，但经过淘宝公司的深度开发已不同于普通的网络数据，产品所提供的数据内容不再是原始网络数据，而是在巨量原始网络数据基础设通过一定的算法，经过深度分析过滤、提炼整合以及匿名化脱敏处理后而形成预测性、指数型、统计型的衍生数据；其次，该产品呈现内容的方式是趋势图、排行榜、占比图等图形，提供的是可视化的数据内容，“生意参谋”数据产品将巨量枯燥的原始网络数据通过一定的算法过滤，整合成适应市场需求的数据内容，形成大数据分析，并直观地呈现给用户，能够给用户全新的感知体验，其已不是一般意义上的网络数据库，已成为网络大数据产品。

（2）数据收集者收集和使用原则

1. 收集者明确使用目的并获得用户同意
2. 不做他用、或者为其他用途获得同意

网络运营者对于原始网络数据仍应受制于网络用户对于其所提供的用户信息的控制，而不能享有独立的权利，网络运营者只能依其与网络用户的约定享有对原始网络数据的使用权

（3）数据收集者需要保护访问控制

1. 数据只能被有相应权限的使用者访问
2. 用户自身的访问控制不受损害

GDPR第一案：脸书技术漏洞调查

（4）终止数据收集者的所有权

1. 数据主体有权删除个人数据（删除权）
2. 数据主体有权要求删除个人数据（被遗忘权）